{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graph_lstm_baseline_covid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMkHBlDJ7Nch6AVFfwsTq3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bachnguyenTE/temporal-mgn/blob/prototype-mgvae/baselines/graph_lstm_baseline_covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB2BzbL_vxv3",
        "outputId": "48686ce6-707b-4c52-8d50-ccaaea26dda1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 14 00:49:07 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "!ls drive/MyDrive/Research/TMGN/model_checkpoints/baseline_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR38v4zFu9St",
        "outputId": "303ccc86-714f-4aae-e057-c82d66411470"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "graph_lstm  t_gcn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT_DIR=\"drive/MyDrive/Research/TMGN/model_checkpoints/baseline_models/graph_lstm/\""
      ],
      "metadata": {
        "id": "YNWDEwjEvbTN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "%%capture\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric \n",
        "!pip install torch-geometric-temporal\n",
        "\n",
        "!pip install einops\n",
        "!wget -c https://gist.githubusercontent.com/Luvata/55f7b3e9ae451122b9e3faf0a7387b4f/raw/440fac5c6e7153fd39e4eb9ebec6e51c9520ef1f/visualize.py\n",
        "!pip install --upgrade graphviz\n",
        "\n",
        "!pip install wandb -qqq\n",
        "!pip install prettytable"
      ],
      "metadata": {
        "id": "HtVqGUZjv2We"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric_temporal.nn.recurrent import GConvLSTM\n",
        "\n",
        "from torch_geometric_temporal.dataset import EnglandCovidDatasetLoader\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "import wandb\n",
        "import datetime"
      ],
      "metadata": {
        "id": "QEhDN53RyBp1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "6NpnyKna1FYi",
        "outputId": "9697c71f-3e68-46bd-c472-1b9c8cac67b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"graph-lstm-baseline-covid\", entity=\"bachnguyen\")\n",
        "wandb.config = {\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"epochs\": 200,\n",
        "    \"batch_size\": 1\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "11I4hzX71HDx",
        "outputId": "4f4d3328-c85f-472c-f57d-3e1211f971d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbachnguyen\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220414_005003-36pcx23q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachnguyen/graph-lstm-baseline-covid/runs/36pcx23q\" target=\"_blank\">amber-breeze-1</a></strong> to <a href=\"https://wandb.ai/bachnguyen/graph-lstm-baseline-covid\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: \n",
        "            continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ],
      "metadata": {
        "id": "E5AlMkUC39X2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix all random seed\n",
        "torch_geometric.seed.seed_everything(69420)\n",
        "\n",
        "# Set device to gpu\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "MPmFnaiC_Ngx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = EnglandCovidDatasetLoader()\n",
        "dataset = loader.get_dataset()\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
      ],
      "metadata": {
        "id": "_skC8MVgzuaC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentGCN(torch.nn.Module):\n",
        "    def __init__(self, node_features):\n",
        "        super(RecurrentGCN, self).__init__()\n",
        "        self.recurrent = GConvLSTM(node_features, 64, 1)\n",
        "        self.linear = torch.nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight, h, c):\n",
        "        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n",
        "        h = F.relu(h_0)\n",
        "        h = self.linear(h)\n",
        "        return h, h_0, c_0"
      ],
      "metadata": {
        "id": "fX5jb6-Oz8Jv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecurrentGCN(node_features=8).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "model.train()\n",
        "\n",
        "param_count = count_parameters(model)\n",
        "\n",
        "for epoch in tqdm(range(50)):\n",
        "    cost = 0\n",
        "    h, c = None, None\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        snapshot.to(device)\n",
        "        y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n",
        "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "    cost = cost / (time+1)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Log metrics\n",
        "    wandb.log({\"loss\": cost})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xBJ4VJq0CH_",
        "outputId": "cb157e00-daee-49f1-a548-ce5320055305"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+------------+\n",
            "|             Modules              | Parameters |\n",
            "+----------------------------------+------------+\n",
            "|         recurrent.w_c_i          |     64     |\n",
            "|          recurrent.b_i           |     64     |\n",
            "|         recurrent.w_c_f          |     64     |\n",
            "|          recurrent.b_f           |     64     |\n",
            "|          recurrent.b_c           |     64     |\n",
            "|         recurrent.w_c_o          |     64     |\n",
            "|          recurrent.b_o           |     64     |\n",
            "|     recurrent.conv_x_i.bias      |     64     |\n",
            "| recurrent.conv_x_i.lins.0.weight |    512     |\n",
            "|     recurrent.conv_h_i.bias      |     64     |\n",
            "| recurrent.conv_h_i.lins.0.weight |    4096    |\n",
            "|     recurrent.conv_x_f.bias      |     64     |\n",
            "| recurrent.conv_x_f.lins.0.weight |    512     |\n",
            "|     recurrent.conv_h_f.bias      |     64     |\n",
            "| recurrent.conv_h_f.lins.0.weight |    4096    |\n",
            "|     recurrent.conv_x_c.bias      |     64     |\n",
            "| recurrent.conv_x_c.lins.0.weight |    512     |\n",
            "|     recurrent.conv_h_c.bias      |     64     |\n",
            "| recurrent.conv_h_c.lins.0.weight |    4096    |\n",
            "|     recurrent.conv_x_o.bias      |     64     |\n",
            "| recurrent.conv_x_o.lins.0.weight |    512     |\n",
            "|     recurrent.conv_h_o.bias      |     64     |\n",
            "| recurrent.conv_h_o.lins.0.weight |    4096    |\n",
            "|          linear.weight           |     64     |\n",
            "|           linear.bias            |     1      |\n",
            "+----------------------------------+------------+\n",
            "Total Trainable Params: 19457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOW = datetime.datetime.now()\n",
        "timestamp = NOW.isoformat().replace(\":\", \"_\")\n",
        "print(timestamp)\n",
        "print('Saving trained model...')\n",
        "torch.save(model.state_dict(), DATA_ROOT_DIR+f\"graph_lstm_covid_{timestamp}.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi4cAUzJ3u9U",
        "outputId": "ff421cab-6313-4623-fd84-926092abde7c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-14T00_55_08.252534\n",
            "Saving trained model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "cost = 0\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    snapshot.to(device)\n",
        "    y_hat, h, c = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h, c)\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "cost = cost / (time+1)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ65HNxf0FiY",
        "outputId": "98ba42bf-4e88-415f-bbda-83df8a900f3e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.0079\n"
          ]
        }
      ]
    }
  ]
}