{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t_gcn_baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOai9YneQRx0kT2PDh9gmNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bachnguyenTE/temporal-mgn/blob/prototype-mgvae/baselines/t_gcn_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB2BzbL_vxv3",
        "outputId": "51d79427-951d-45f0-a6a9-3d0a8bb662ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 12 10:48:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "%%capture\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric \n",
        "!pip install torch-geometric-temporal\n",
        "\n",
        "!pip install einops\n",
        "!wget -c https://gist.githubusercontent.com/Luvata/55f7b3e9ae451122b9e3faf0a7387b4f/raw/440fac5c6e7153fd39e4eb9ebec6e51c9520ef1f/visualize.py\n",
        "!pip install --upgrade graphviz\n",
        "\n",
        "!pip install wandb -qqq\n",
        "!pip install prettytable"
      ],
      "metadata": {
        "id": "HtVqGUZjv2We"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric_temporal.nn.recurrent import TGCN\n",
        "\n",
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "from torch_geometric_temporal.dataset import WindmillOutputLargeDatasetLoader\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "import wandb"
      ],
      "metadata": {
        "id": "QEhDN53RyBp1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "6NpnyKna1FYi",
        "outputId": "90b7e6b7-7153-4a35-8cc4-b971ad90bd3b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"t-gcn-baseline\", entity=\"bachnguyen\")\n",
        "wandb.config = {\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"epochs\": 50,\n",
        "    \"batch_size\": 1\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "11I4hzX71HDx",
        "outputId": "813f538d-6a0d-4e4f-d09f-780f33ff28a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbachnguyen\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_105148-1md99kmu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachnguyen/t-gcn-baseline/runs/1md99kmu\" target=\"_blank\">misty-spaceship-2</a></strong> to <a href=\"https://wandb.ai/bachnguyen/t-gcn-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: \n",
        "            continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ],
      "metadata": {
        "id": "E5AlMkUC39X2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_geometric.seed.seed_everything(0)"
      ],
      "metadata": {
        "id": "EyJjacWAV4-V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WindmillOutputLargeDatasetLoader()\n",
        "dataset = loader.get_dataset()\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)"
      ],
      "metadata": {
        "id": "_skC8MVgzuaC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentGCN(torch.nn.Module):\n",
        "    def __init__(self, node_features):\n",
        "        super(RecurrentGCN, self).__init__()\n",
        "        self.recurrent = TGCN(node_features, 64)\n",
        "        self.linear = torch.nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        h = self.recurrent(x, edge_index, edge_weight)\n",
        "        h = F.relu(h)\n",
        "        h = self.linear(h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "fX5jb6-Oz8Jv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecurrentGCN(node_features = 8)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(50)):\n",
        "    cost = 0\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "    cost = cost / (time+1)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Log metrics\n",
        "    wandb.log({\"loss\": cost})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xBJ4VJq0CH_",
        "outputId": "dbaaa9c2-1f3b-4116-d795-cb03892da736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_count = count_parameters(model)"
      ],
      "metadata": {
        "id": "4XrrTkiO3UZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "cost = 0\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "cost = cost / (time+1)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))"
      ],
      "metadata": {
        "id": "wJ65HNxf0FiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}