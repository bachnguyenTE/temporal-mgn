{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "temporal_mgvae_attention.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtQlnR+CnZjr8plB29Ar96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bachnguyenTE/temporal-mgn/blob/prototype-mgvae/temporal_mgvae_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuoLHm2oa_zC",
        "outputId": "85fabd67-1623-4792-dd15-c08725c047ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 00:04:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arguments (inactive)\n",
        "\n",
        "# def _parse_args():\n",
        "#     parser = argparse.ArgumentParser(description = 'Temporal graph learning')\n",
        "#     parser.add_argument('--dir', '-dir', type = str, default = '.', help = 'Directory')\n",
        "#     parser.add_argument('--learning_target', '-learning_target', type = str, default = 'U0', help = 'Learning target')\n",
        "#     parser.add_argument('--name', '-name', type = str, default = 'NAME', help = 'Name')\n",
        "#     parser.add_argument('--dataset', '-dataset', type = str, default = 'ZINC_12k', help = 'ZINC')\n",
        "#     parser.add_argument('--num_epoch', '-num_epoch', type = int, default = 2048, help = 'Number of epochs')\n",
        "#     parser.add_argument('--batch_size', '-batch_size', type = int, default = 20, help = 'Batch size')\n",
        "#     parser.add_argument('--learning_rate', '-learning_rate', type = float, default = 0.001, help = 'Initial learning rate')\n",
        "#     parser.add_argument('--seed', '-s', type = int, default = 123456789, help = 'Random seed')\n",
        "#     parser.add_argument('--n_clusters', '-n_clusters', type = int, default = 2, help = 'Number of clusters')\n",
        "#     parser.add_argument('--n_levels', '-n_levels', type = int, default = 3, help = 'Number of levels of resolution')\n",
        "#     parser.add_argument('--n_layers', '-n_layers', type = int, default = 3, help = 'Number of layers of message passing')\n",
        "#     parser.add_argument('--hidden_dim', '-hidden_dim', type = int, default = 32, help = 'Hidden dimension')\n",
        "#     parser.add_argument('--z_dim', '-z_dim', type = int, default = 32, help = 'Latent dimension')\n",
        "#     parser.add_argument('--device', '-device', type = str, default = 'cpu', help = 'cuda/cpu')\n",
        "#     args = parser.parse_args()\n",
        "#     return args\n",
        "\n",
        "# args = _parse_args()\n",
        "# log_name = args.dir + \"/\" + args.name + \".log\"\n",
        "# model_name = args.dir + \"/\" + args.name + \".model\"\n",
        "# LOG = open(log_name, \"w\")"
      ],
      "metadata": {
        "id": "p70wMn16dXq-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "%%capture\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric \n",
        "!pip install torch-geometric-temporal\n",
        "\n",
        "!pip install einops\n",
        "!wget -c https://gist.githubusercontent.com/Luvata/55f7b3e9ae451122b9e3faf0a7387b4f/raw/440fac5c6e7153fd39e4eb9ebec6e51c9520ef1f/visualize.py\n",
        "!pip install --upgrade graphviz\n",
        "\n",
        "!pip install wandb -qqq\n",
        "!pip install prettytable"
      ],
      "metadata": {
        "id": "izcOBzw6bCDv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Library import (legacy MGVAE)\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, Adagrad\n",
        "import pickle\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "from torch.nn import MultiheadAttention\n",
        "\n",
        "# Library import (pytorch-geometric)\n",
        "import torch_geometric \n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.loader import DataLoader, ClusterLoader, ClusterData\n",
        "from torch_geometric.nn import MessagePassing, GCNConv, GATConv\n",
        "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
        "\n",
        "###############################################################\n",
        "# NOTE: \n",
        "# We preferably define our own clustering \n",
        "# procedure, rather than using the built-in ClusterLoader\n",
        "# since there is a chance using ClusterLoader will not\n",
        "# make the entire net differentiable (separate data process),\n",
        "# and the net may no longer be isomorphic invariant.\n",
        "###############################################################\n",
        "\n",
        "from visualize import display_module\n",
        "import wandb\n",
        "import datetime\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "4Bw6mX9dbcwf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "ZMTvkOXKEdck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a1e25b2e-ec7f-4a93-d8f7-bcfb15ff2b22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"temporal-mgn-attention-chickenpox\", entity=\"temporal-graph-research\")\n",
        "wandb.config = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 350,\n",
        "    \"batch_size\": 1\n",
        "}"
      ],
      "metadata": {
        "id": "TIM_ULu2EevT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7e2bdbd0-40ef-47ec-fb1b-3ed1bb4abeab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtemporal-graph-research\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220426_000501-1rlnd1vu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/temporal-graph-research/temporal-mgn-attention-chickenpox/runs/1rlnd1vu\" target=\"_blank\">denim-dew-11</a></strong> to <a href=\"https://wandb.ai/temporal-graph-research/temporal-mgn-attention-chickenpox\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: \n",
        "            continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ],
      "metadata": {
        "id": "L8HMonkoEpcB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix all random seed\n",
        "torch_geometric.seed.seed_everything(69420)\n",
        "\n",
        "# Set device to gpu\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "PjiJCDQ5h_ww"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "loader = ChickenpoxDatasetLoader()\n",
        "\n",
        "dataset = loader.get_dataset()\n",
        "\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
      ],
      "metadata": {
        "id": "G24AQl_u0oN0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define glorot initialization\n",
        "def glorot_init(input_dim, output_dim):\n",
        "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
        "    initial = torch.rand(input_dim, output_dim) * 2 * init_range - init_range\n",
        "    return nn.Parameter(initial)"
      ],
      "metadata": {
        "id": "ERrvyJPjJug1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiresolution Graph Network\n",
        "class MGN(nn.Module):\n",
        "    def __init__(self, clusters, num_layers, node_dim, edge_dim, hidden_dim, z_dim, num_classes):\n",
        "        super(MGN, self).__init__()\n",
        "        self.clusters = clusters\n",
        "        self.num_layers = num_layers\n",
        "        self.node_dim = node_dim\n",
        "        self.edge_dim = edge_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.base_encoder = GraphEncoder(self.num_layers, self.node_dim, self.edge_dim, self.hidden_dim, self.z_dim)\n",
        "\n",
        "        self.cluster_learner = nn.ModuleList()\n",
        "        self.global_encoder = nn.ModuleList()\n",
        "        for i in range(len(self.clusters)):\n",
        "            N = self.clusters[i]\n",
        "            self.cluster_learner.append(GraphCluster(self.num_layers, self.z_dim, self.hidden_dim, N))\n",
        "            if edge_dim is not None:\n",
        "                self.global_encoder.append(GraphEncoder(self.num_layers, self.z_dim, self.hidden_dim, self.hidden_dim, self.z_dim))\n",
        "            else:\n",
        "                self.global_encoder.append(GraphEncoder(self.num_layers, self.z_dim, None, self.hidden_dim, self.z_dim))\n",
        "\n",
        "        self.vertical_attention = MultiheadAttention(self.z_dim, 1, batch_first=True)\n",
        "\n",
        "        D = self.z_dim * (len(self.clusters) + 1)\n",
        "        self.fc1 = nn.Linear(self.z_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, adj, node_feat, edge_feat = None):\n",
        "        outputs = []\n",
        "\n",
        "        # Base encoder\n",
        "        base_latent, base_edge_hidden = self.base_encoder(adj, node_feat, edge_feat)\n",
        "\n",
        "        outputs.append([base_latent, adj, base_edge_hidden])\n",
        "\n",
        "        l = 0\n",
        "        while l < len(self.clusters):\n",
        "            if l == 0:\n",
        "                prev_adj = adj\n",
        "                prev_latent = base_latent\n",
        "                prev_edge_hidden = base_edge_hidden\n",
        "            else:\n",
        "                prev_adj = outputs[len(outputs) - 1][1]\n",
        "                prev_latent = outputs[len(outputs) - 1][0]\n",
        "                prev_edge_hidden = outputs[len(outputs) - 1][2]\n",
        "\n",
        "            # Assignment score\n",
        "            assign_score = self.cluster_learner[l](prev_adj, prev_latent)\n",
        "\n",
        "            # Softmax (soft assignment)\n",
        "            # assign_matrix = F.softmax(assign_score, dim = 2)\n",
        "\n",
        "            # Gumbel softmax (hard assignment)\n",
        "            assign_matrix = F.gumbel_softmax(assign_score, tau = 1, hard = True, dim = 1)\n",
        "\n",
        "            # Print out the cluster assignment matrix\n",
        "            # print(torch.sum(assign_matrix, dim = 0))\n",
        "\n",
        "            # Shrinked latent\n",
        "            shrinked_latent = torch.matmul(assign_matrix.transpose(0, 1), prev_latent)\n",
        "\n",
        "            # Latent normalization\n",
        "            shrinked_latent = F.normalize(shrinked_latent, dim = 0)\n",
        "\n",
        "            # Shrinked adjacency\n",
        "            # print(f'Iteration: {l}')\n",
        "            # print(to_dense_adj(prev_adj))\n",
        "            # print(f'to_dense_adj size: {to_dense_adj(prev_adj, max_num_nodes=self.clusters[l]).size()}')\n",
        "            # print(f'assign_matrix size: {assign_matrix.size()}')\n",
        "            # print(f'node_feat size: {node_feat.size()}')\n",
        "            # print(f'adj size: {prev_adj.size()}')\n",
        "            # print(f'prev_adj size: {prev_adj.size()}')\n",
        "            if l == 0:\n",
        "                shrinked_adj = torch.einsum('sdf,st->tdf', torch.matmul(assign_matrix.transpose(0, 1), to_dense_adj(prev_adj, edge_attr = prev_edge_hidden, max_num_nodes=node_feat.size()[0])[0]), assign_matrix)\n",
        "            else:\n",
        "                shrinked_adj = torch.einsum('sdf,st->tdf', torch.matmul(assign_matrix.transpose(0, 1), to_dense_adj(prev_adj, edge_attr = prev_edge_hidden, max_num_nodes=self.clusters[l - 1])[0]), assign_matrix)\n",
        "                # shrinked_adj = torch.matmul(torch.matmul(assign_matrix.transpose(0, 1), to_dense_adj(prev_adj, edge_attr=prev_edge_hidden, max_num_nodes=self.clusters[l - 1])[0]), assign_matrix)\n",
        "\n",
        "            # Adjacency normalization\n",
        "            shrinked_adj = shrinked_adj / torch.sum(shrinked_adj)\n",
        "\n",
        "            # Reformatting adjacency matrix as edge index\n",
        "            shrinked_edge_indices = torch.stack(torch.sum(shrinked_adj, dim=2).nonzero(as_tuple=True), dim=0)\n",
        "            shrinked_edge_hidden = shrinked_adj[shrinked_edge_indices[0], shrinked_edge_indices[1], :]\n",
        "\n",
        "            # Global encoder\n",
        "            next_latent, next_edge_hidden = self.global_encoder[l](shrinked_edge_indices, shrinked_latent, shrinked_edge_hidden)\n",
        "\n",
        "            outputs.append([next_latent, shrinked_edge_indices, next_edge_hidden])\n",
        "            l += 1\n",
        "\n",
        "        # Scalar prediction with vertical attention\n",
        "        latents = torch.stack([torch.sum(output[0], dim = 0) for output in outputs], dim = 0)\n",
        "        latents = latents[None, :]\n",
        "        att_latents, _ = self.vertical_attention(latents, latents, latents)\n",
        "        output_latents = torch.mean(att_latents[0], dim=0)\n",
        "        hidden = torch.tanh(self.fc1(output_latents))\n",
        "        predict = self.fc2(hidden)\n",
        "\n",
        "        return predict, output_latents, outputs"
      ],
      "metadata": {
        "id": "0unZS5oei86U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph encoder block\n",
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(self, num_layers, node_dim, edge_dim, hidden_dim, z_dim, use_concat_layer=True, **kwargs):\n",
        "        super(GraphEncoder, self).__init__(**kwargs)\n",
        "        self.num_layers = num_layers\n",
        "        self.node_dim = node_dim\n",
        "        self.edge_dim = edge_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.use_concat_layer = use_concat_layer\n",
        "\n",
        "        self.node_fc1 = nn.Linear(self.node_dim, 128)\n",
        "        self.node_fc2 = nn.Linear(128, self.hidden_dim)\n",
        "\n",
        "        if self.edge_dim is not None:\n",
        "            self.edge_fc1 = nn.Linear(self.edge_dim, 128)\n",
        "            self.edge_fc2 = nn.Linear(128, self.hidden_dim)\n",
        "\n",
        "        self.base_net = nn.ModuleList()\n",
        "        self.combine_net = nn.ModuleList()\n",
        "        for layer in range(self.num_layers):\n",
        "            self.base_net.append(GATConv(self.hidden_dim, self.hidden_dim, edge_dim=self.hidden_dim))\n",
        "\n",
        "        if self.use_concat_layer == True:\n",
        "            self.latent_fc1 = nn.Linear((self.num_layers + 1) * self.hidden_dim, 256)\n",
        "            self.latent_fc2 = nn.Linear(256, self.z_dim)\n",
        "        else:\n",
        "            self.latent_fc1 = nn.Linear(self.hidden_dim, 256)\n",
        "            self.latent_fc2 = nn.Linear(256, self.z_dim)\n",
        "\n",
        "    def forward(self, adj, node_feat, edge_feat=None):\n",
        "        node_hidden = torch.tanh(self.node_fc1(node_feat))\n",
        "        node_hidden = torch.tanh(self.node_fc2(node_hidden))\n",
        "\n",
        "        if edge_feat is not None and self.edge_dim is not None:\n",
        "            edge_hidden = torch.tanh(self.edge_fc1(edge_feat))\n",
        "            edge_hidden = torch.tanh(self.edge_fc2(edge_hidden))\n",
        "        else:\n",
        "            edge_hidden = None\n",
        "\n",
        "        all_hidden = [node_hidden]\n",
        "\n",
        "        if edge_feat is not None:\n",
        "            for layer in range(len(self.base_net)):\n",
        "                if layer == 0:\n",
        "                    hidden = self.base_net[layer](node_hidden, adj, edge_hidden)\n",
        "                else:\n",
        "                    hidden = self.base_net[layer](hidden, adj, edge_hidden)\n",
        "            \n",
        "                all_hidden.append(hidden)\n",
        "        else:\n",
        "            for layer in range(len(self.base_net)):\n",
        "                if layer == 0:\n",
        "                    hidden = self.base_net[layer](node_hidden, adj)\n",
        "                else:\n",
        "                    hidden = self.base_net[layer](hidden, adj)\n",
        "            \n",
        "                all_hidden.append(hidden)\n",
        "\n",
        "        if self.use_concat_layer == True:\n",
        "            hidden = torch.cat(all_hidden, dim=1)\n",
        "\n",
        "        latent = torch.tanh(self.latent_fc1(hidden))\n",
        "        latent = torch.tanh(self.latent_fc2(latent))\n",
        "        return latent, edge_hidden"
      ],
      "metadata": {
        "id": "PK0GXjEK_zqq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph clustering block\n",
        "class GraphCluster(nn.Module):\n",
        "    def __init__(self, num_layers, input_dim, hidden_dim, z_dim, **kwargs):\n",
        "        super(GraphCluster, self).__init__(**kwargs)\n",
        "        self.num_layers = num_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.fc1 = nn.Linear(self.input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, self.hidden_dim)\n",
        "\n",
        "        # Option 1: Learnable clustering\n",
        "        self.base_net = nn.ModuleList()\n",
        "        \n",
        "        # Option 2: Fixed clustering\n",
        "        # self.base_net = []\n",
        "\n",
        "        for layer in range(self.num_layers):\n",
        "            self.base_net.append(GCNConv(self.hidden_dim, self.hidden_dim))\n",
        "\n",
        "        self.assign_net = GCNConv(self.hidden_dim, self.z_dim)\n",
        "\n",
        "    def forward(self, adj, X):\n",
        "        hidden = torch.sigmoid(self.fc1(X))\n",
        "        hidden = torch.sigmoid(self.fc2(hidden))\n",
        "        for net in self.base_net:\n",
        "            hidden = net(hidden, adj)\n",
        "        assign = self.assign_net(hidden, adj)\n",
        "        return assign"
      ],
      "metadata": {
        "id": "zr-QR7HkGfNh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalMGN(nn.Module):\n",
        "    def __init__(self, clusters, num_layers, node_dim, edge_dim, hidden_dim, z_dim, num_classes, time_seq_length):\n",
        "        super(TemporalMGN, self).__init__()\n",
        "        self.clusters = clusters\n",
        "        self.num_layers = num_layers\n",
        "        self.node_dim = node_dim\n",
        "        self.edge_dim = edge_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.time_seq_length = time_seq_length\n",
        "\n",
        "        self.attention_multires = MGN(self.clusters, self.num_layers, self.node_dim, self.edge_dim, self.hidden_dim, self.z_dim, self.num_classes)\n",
        "        self.horizontal_attention = MultiheadAttention(self.z_dim, 1, batch_first=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.z_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, time_step: int, graph_seq_embed, graph_seq_mask, adj, node_feat, edge_feat=None):\n",
        "        _, multires_latents, _ = self.attention_multires(adj, node_feat, edge_feat)\n",
        "        if time_step is not 0:\n",
        "            graph_seq_embed = torch.cat([graph_seq_embed, multires_latents[None, :]], dim=0)\n",
        "        else:\n",
        "            graph_seq_embed = multires_latents[None, :]\n",
        "\n",
        "        attn_embed = graph_seq_embed[None, :].to(device)\n",
        "        horizontal_attn_latents, _ = self.horizontal_attention(attn_embed, attn_embed, attn_embed)\n",
        "        output_latents = torch.mean(horizontal_attn_latents[0], dim=0)\n",
        "        hidden = torch.tanh(self.fc1(output_latents))\n",
        "        predict = self.fc2(hidden)\n",
        "\n",
        "        return predict, multires_latents[None, :]"
      ],
      "metadata": {
        "id": "DEegfwT_NTb-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adj is the adjacency matrix\n",
        "# PyG: need to convert graph data format to the adjacency matrix format, or rewrite code"
      ],
      "metadata": {
        "id": "4eTq69e6_3Mb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_steps_count = 258\n",
        "mask_tensor = torch.empty((time_steps_count, time_steps_count, time_steps_count))\n",
        "print(mask_tensor.size())\n",
        "\n",
        "for i in range(time_steps_count):\n",
        "    time_len = i + 1\n",
        "    mask = (torch.triu(torch.ones(time_len, time_len)) == 1).transpose(0, 1).float()\n",
        "    mask = F.pad(mask, (0, time_steps_count-time_len, 0, time_steps_count-time_len), \"constant\", 0)\n",
        "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    mask_tensor[i] = mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7nCzaeKxj3S",
        "outputId": "b371188b-43bb-40c3-8e4c-96b1ee84ac05"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([258, 258, 258])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = TemporalMGN(\n",
        "    clusters=[4],\n",
        "    num_layers=4,\n",
        "    node_dim=4,\n",
        "    edge_dim=1,\n",
        "    hidden_dim=64,\n",
        "    z_dim=16,\n",
        "    num_classes=20,\n",
        "    time_seq_length = time_steps_count\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "param_count = count_parameters(model)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(350):\n",
        "    cost = 0\n",
        "    graph_seq_embed_list = []\n",
        "    masking = mask_tensor\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        masking.to(device)\n",
        "        snapshot.to(device)\n",
        "        if time == 0:\n",
        "            graph_seq_embed = torch.empty((0, 0)).to(device)\n",
        "        else: \n",
        "            graph_seq_embed = torch.cat(graph_seq_embed_list, dim=0).to(device)\n",
        "        y_hat, cur_graph_seq_embed = model(time, graph_seq_embed, masking[time].to(device), snapshot.edge_index, snapshot.x, snapshot.edge_attr[:, None])\n",
        "        # print(f\"y_hat size: {y_hat.size()}\")\n",
        "        # print(f\"y_hat: {y_hat}\")\n",
        "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "        graph_seq_embed_list.append(cur_graph_seq_embed)\n",
        "    cost = cost / (time+1)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    wandb.log({\"train_loss\": cost})\n",
        "    print(f'Epoch: {epoch:03d}, Train Loss: {cost:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "3i-OmrF5u16M",
        "outputId": "0a3e051a-f3e0-435c-d609-2ef67e0a3e62"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------+------------+\n",
            "|                            Modules                             | Parameters |\n",
            "+----------------------------------------------------------------+------------+\n",
            "|        attention_multires.base_encoder.node_fc1.weight         |    512     |\n",
            "|         attention_multires.base_encoder.node_fc1.bias          |    128     |\n",
            "|        attention_multires.base_encoder.node_fc2.weight         |    8192    |\n",
            "|         attention_multires.base_encoder.node_fc2.bias          |     64     |\n",
            "|        attention_multires.base_encoder.edge_fc1.weight         |    128     |\n",
            "|         attention_multires.base_encoder.edge_fc1.bias          |    128     |\n",
            "|        attention_multires.base_encoder.edge_fc2.weight         |    8192    |\n",
            "|         attention_multires.base_encoder.edge_fc2.bias          |     64     |\n",
            "|       attention_multires.base_encoder.base_net.0.att_src       |     64     |\n",
            "|       attention_multires.base_encoder.base_net.0.att_dst       |     64     |\n",
            "|      attention_multires.base_encoder.base_net.0.att_edge       |     64     |\n",
            "|        attention_multires.base_encoder.base_net.0.bias         |     64     |\n",
            "|   attention_multires.base_encoder.base_net.0.lin_src.weight    |    4096    |\n",
            "|   attention_multires.base_encoder.base_net.0.lin_edge.weight   |    4096    |\n",
            "|       attention_multires.base_encoder.base_net.1.att_src       |     64     |\n",
            "|       attention_multires.base_encoder.base_net.1.att_dst       |     64     |\n",
            "|      attention_multires.base_encoder.base_net.1.att_edge       |     64     |\n",
            "|        attention_multires.base_encoder.base_net.1.bias         |     64     |\n",
            "|   attention_multires.base_encoder.base_net.1.lin_src.weight    |    4096    |\n",
            "|   attention_multires.base_encoder.base_net.1.lin_edge.weight   |    4096    |\n",
            "|       attention_multires.base_encoder.base_net.2.att_src       |     64     |\n",
            "|       attention_multires.base_encoder.base_net.2.att_dst       |     64     |\n",
            "|      attention_multires.base_encoder.base_net.2.att_edge       |     64     |\n",
            "|        attention_multires.base_encoder.base_net.2.bias         |     64     |\n",
            "|   attention_multires.base_encoder.base_net.2.lin_src.weight    |    4096    |\n",
            "|   attention_multires.base_encoder.base_net.2.lin_edge.weight   |    4096    |\n",
            "|       attention_multires.base_encoder.base_net.3.att_src       |     64     |\n",
            "|       attention_multires.base_encoder.base_net.3.att_dst       |     64     |\n",
            "|      attention_multires.base_encoder.base_net.3.att_edge       |     64     |\n",
            "|        attention_multires.base_encoder.base_net.3.bias         |     64     |\n",
            "|   attention_multires.base_encoder.base_net.3.lin_src.weight    |    4096    |\n",
            "|   attention_multires.base_encoder.base_net.3.lin_edge.weight   |    4096    |\n",
            "|       attention_multires.base_encoder.latent_fc1.weight        |   81920    |\n",
            "|        attention_multires.base_encoder.latent_fc1.bias         |    256     |\n",
            "|       attention_multires.base_encoder.latent_fc2.weight        |    4096    |\n",
            "|        attention_multires.base_encoder.latent_fc2.bias         |     16     |\n",
            "|        attention_multires.cluster_learner.0.fc1.weight         |    2048    |\n",
            "|         attention_multires.cluster_learner.0.fc1.bias          |    128     |\n",
            "|        attention_multires.cluster_learner.0.fc2.weight         |    8192    |\n",
            "|         attention_multires.cluster_learner.0.fc2.bias          |     64     |\n",
            "|      attention_multires.cluster_learner.0.base_net.0.bias      |     64     |\n",
            "|   attention_multires.cluster_learner.0.base_net.0.lin.weight   |    4096    |\n",
            "|      attention_multires.cluster_learner.0.base_net.1.bias      |     64     |\n",
            "|   attention_multires.cluster_learner.0.base_net.1.lin.weight   |    4096    |\n",
            "|      attention_multires.cluster_learner.0.base_net.2.bias      |     64     |\n",
            "|   attention_multires.cluster_learner.0.base_net.2.lin.weight   |    4096    |\n",
            "|      attention_multires.cluster_learner.0.base_net.3.bias      |     64     |\n",
            "|   attention_multires.cluster_learner.0.base_net.3.lin.weight   |    4096    |\n",
            "|      attention_multires.cluster_learner.0.assign_net.bias      |     4      |\n",
            "|   attention_multires.cluster_learner.0.assign_net.lin.weight   |    256     |\n",
            "|      attention_multires.global_encoder.0.node_fc1.weight       |    2048    |\n",
            "|       attention_multires.global_encoder.0.node_fc1.bias        |    128     |\n",
            "|      attention_multires.global_encoder.0.node_fc2.weight       |    8192    |\n",
            "|       attention_multires.global_encoder.0.node_fc2.bias        |     64     |\n",
            "|      attention_multires.global_encoder.0.edge_fc1.weight       |    8192    |\n",
            "|       attention_multires.global_encoder.0.edge_fc1.bias        |    128     |\n",
            "|      attention_multires.global_encoder.0.edge_fc2.weight       |    8192    |\n",
            "|       attention_multires.global_encoder.0.edge_fc2.bias        |     64     |\n",
            "|     attention_multires.global_encoder.0.base_net.0.att_src     |     64     |\n",
            "|     attention_multires.global_encoder.0.base_net.0.att_dst     |     64     |\n",
            "|    attention_multires.global_encoder.0.base_net.0.att_edge     |     64     |\n",
            "|      attention_multires.global_encoder.0.base_net.0.bias       |     64     |\n",
            "| attention_multires.global_encoder.0.base_net.0.lin_src.weight  |    4096    |\n",
            "| attention_multires.global_encoder.0.base_net.0.lin_edge.weight |    4096    |\n",
            "|     attention_multires.global_encoder.0.base_net.1.att_src     |     64     |\n",
            "|     attention_multires.global_encoder.0.base_net.1.att_dst     |     64     |\n",
            "|    attention_multires.global_encoder.0.base_net.1.att_edge     |     64     |\n",
            "|      attention_multires.global_encoder.0.base_net.1.bias       |     64     |\n",
            "| attention_multires.global_encoder.0.base_net.1.lin_src.weight  |    4096    |\n",
            "| attention_multires.global_encoder.0.base_net.1.lin_edge.weight |    4096    |\n",
            "|     attention_multires.global_encoder.0.base_net.2.att_src     |     64     |\n",
            "|     attention_multires.global_encoder.0.base_net.2.att_dst     |     64     |\n",
            "|    attention_multires.global_encoder.0.base_net.2.att_edge     |     64     |\n",
            "|      attention_multires.global_encoder.0.base_net.2.bias       |     64     |\n",
            "| attention_multires.global_encoder.0.base_net.2.lin_src.weight  |    4096    |\n",
            "| attention_multires.global_encoder.0.base_net.2.lin_edge.weight |    4096    |\n",
            "|     attention_multires.global_encoder.0.base_net.3.att_src     |     64     |\n",
            "|     attention_multires.global_encoder.0.base_net.3.att_dst     |     64     |\n",
            "|    attention_multires.global_encoder.0.base_net.3.att_edge     |     64     |\n",
            "|      attention_multires.global_encoder.0.base_net.3.bias       |     64     |\n",
            "| attention_multires.global_encoder.0.base_net.3.lin_src.weight  |    4096    |\n",
            "| attention_multires.global_encoder.0.base_net.3.lin_edge.weight |    4096    |\n",
            "|     attention_multires.global_encoder.0.latent_fc1.weight      |   81920    |\n",
            "|      attention_multires.global_encoder.0.latent_fc1.bias       |    256     |\n",
            "|     attention_multires.global_encoder.0.latent_fc2.weight      |    4096    |\n",
            "|      attention_multires.global_encoder.0.latent_fc2.bias       |     16     |\n",
            "|      attention_multires.vertical_attention.in_proj_weight      |    768     |\n",
            "|       attention_multires.vertical_attention.in_proj_bias       |     48     |\n",
            "|     attention_multires.vertical_attention.out_proj.weight      |    256     |\n",
            "|      attention_multires.vertical_attention.out_proj.bias       |     16     |\n",
            "|                 attention_multires.fc1.weight                  |    4096    |\n",
            "|                  attention_multires.fc1.bias                   |    256     |\n",
            "|                 attention_multires.fc2.weight                  |    5120    |\n",
            "|                  attention_multires.fc2.bias                   |     20     |\n",
            "|              horizontal_attention.in_proj_weight               |    768     |\n",
            "|               horizontal_attention.in_proj_bias                |     48     |\n",
            "|              horizontal_attention.out_proj.weight              |    256     |\n",
            "|               horizontal_attention.out_proj.bias               |     16     |\n",
            "|                           fc1.weight                           |    1024    |\n",
            "|                            fc1.bias                            |     64     |\n",
            "|                           fc2.weight                           |    1280    |\n",
            "|                            fc2.bias                            |     20     |\n",
            "+----------------------------------------------------------------+------------+\n",
            "Total Trainable Params: 325964\n",
            "Epoch: 000, Train Loss: 1.0849\n",
            "Epoch: 001, Train Loss: 1.0847\n",
            "Epoch: 002, Train Loss: 1.0815\n",
            "Epoch: 003, Train Loss: 1.0797\n",
            "Epoch: 004, Train Loss: 1.0783\n",
            "Epoch: 005, Train Loss: 1.0770\n",
            "Epoch: 006, Train Loss: 1.0761\n",
            "Epoch: 007, Train Loss: 1.0754\n",
            "Epoch: 008, Train Loss: 1.0750\n",
            "Epoch: 009, Train Loss: 1.0745\n",
            "Epoch: 010, Train Loss: 1.0741\n",
            "Epoch: 011, Train Loss: 1.0740\n",
            "Epoch: 012, Train Loss: 1.0740\n",
            "Epoch: 013, Train Loss: 1.0738\n",
            "Epoch: 014, Train Loss: 1.0737\n",
            "Epoch: 015, Train Loss: 1.0737\n",
            "Epoch: 016, Train Loss: 1.0736\n",
            "Epoch: 017, Train Loss: 1.0737\n",
            "Epoch: 018, Train Loss: 1.0734\n",
            "Epoch: 019, Train Loss: 1.0732\n",
            "Epoch: 020, Train Loss: 1.0728\n",
            "Epoch: 021, Train Loss: 1.0722\n",
            "Epoch: 022, Train Loss: 1.0894\n",
            "Epoch: 023, Train Loss: 1.0757\n",
            "Epoch: 024, Train Loss: 1.0760\n",
            "Epoch: 025, Train Loss: 1.0763\n",
            "Epoch: 026, Train Loss: 1.0762\n",
            "Epoch: 027, Train Loss: 1.0752\n",
            "Epoch: 028, Train Loss: 1.0744\n",
            "Epoch: 029, Train Loss: 1.0740\n",
            "Epoch: 030, Train Loss: 1.0738\n",
            "Epoch: 031, Train Loss: 1.0737\n",
            "Epoch: 032, Train Loss: 1.0737\n",
            "Epoch: 033, Train Loss: 1.0737\n",
            "Epoch: 034, Train Loss: 1.0736\n",
            "Epoch: 035, Train Loss: 1.0735\n",
            "Epoch: 036, Train Loss: 1.0734\n",
            "Epoch: 037, Train Loss: 1.0732\n",
            "Epoch: 038, Train Loss: 1.0730\n",
            "Epoch: 039, Train Loss: 1.0729\n",
            "Epoch: 040, Train Loss: 1.0728\n",
            "Epoch: 041, Train Loss: 1.0727\n",
            "Epoch: 042, Train Loss: 1.0725\n",
            "Epoch: 043, Train Loss: 1.0722\n",
            "Epoch: 044, Train Loss: 1.0718\n",
            "Epoch: 045, Train Loss: 1.0715\n",
            "Epoch: 046, Train Loss: 1.0711\n",
            "Epoch: 047, Train Loss: 1.0706\n",
            "Epoch: 048, Train Loss: 1.0701\n",
            "Epoch: 049, Train Loss: 1.0696\n",
            "Epoch: 050, Train Loss: 1.0690\n",
            "Epoch: 051, Train Loss: 1.0685\n",
            "Epoch: 052, Train Loss: 1.0679\n",
            "Epoch: 053, Train Loss: 1.0669\n",
            "Epoch: 054, Train Loss: 1.0659\n",
            "Epoch: 055, Train Loss: 1.0650\n",
            "Epoch: 056, Train Loss: 1.0639\n",
            "Epoch: 057, Train Loss: 1.0673\n",
            "Epoch: 058, Train Loss: 1.0665\n",
            "Epoch: 059, Train Loss: 1.1053\n",
            "Epoch: 060, Train Loss: 1.0876\n",
            "Epoch: 061, Train Loss: 1.0779\n",
            "Epoch: 062, Train Loss: 1.0723\n",
            "Epoch: 063, Train Loss: 1.0794\n",
            "Epoch: 064, Train Loss: 1.0829\n",
            "Epoch: 065, Train Loss: 1.0764\n",
            "Epoch: 066, Train Loss: 1.0722\n",
            "Epoch: 067, Train Loss: 1.0704\n",
            "Epoch: 068, Train Loss: 1.0715\n",
            "Epoch: 069, Train Loss: 1.0703\n",
            "Epoch: 070, Train Loss: 1.0708\n",
            "Epoch: 071, Train Loss: 1.0714\n",
            "Epoch: 072, Train Loss: 1.0715\n",
            "Epoch: 073, Train Loss: 1.0719\n",
            "Epoch: 074, Train Loss: 1.0720\n",
            "Epoch: 075, Train Loss: 1.0718\n",
            "Epoch: 076, Train Loss: 1.0714\n",
            "Epoch: 077, Train Loss: 1.0712\n",
            "Epoch: 078, Train Loss: 1.0712\n",
            "Epoch: 079, Train Loss: 1.0713\n",
            "Epoch: 080, Train Loss: 1.0714\n",
            "Epoch: 081, Train Loss: 1.0711\n",
            "Epoch: 082, Train Loss: 1.0706\n",
            "Epoch: 083, Train Loss: 1.0700\n",
            "Epoch: 084, Train Loss: 1.0699\n",
            "Epoch: 085, Train Loss: 1.0699\n",
            "Epoch: 086, Train Loss: 1.0696\n",
            "Epoch: 087, Train Loss: 1.0691\n",
            "Epoch: 088, Train Loss: 1.0689\n",
            "Epoch: 089, Train Loss: 1.0688\n",
            "Epoch: 090, Train Loss: 1.0684\n",
            "Epoch: 091, Train Loss: 1.0679\n",
            "Epoch: 092, Train Loss: 1.0675\n",
            "Epoch: 093, Train Loss: 1.0671\n",
            "Epoch: 094, Train Loss: 1.0669\n",
            "Epoch: 095, Train Loss: 1.0664\n",
            "Epoch: 096, Train Loss: 1.0667\n",
            "Epoch: 097, Train Loss: 1.0660\n",
            "Epoch: 098, Train Loss: 1.0659\n",
            "Epoch: 099, Train Loss: 1.0655\n",
            "Epoch: 100, Train Loss: 1.0683\n",
            "Epoch: 101, Train Loss: 1.0970\n",
            "Epoch: 102, Train Loss: 1.0797\n",
            "Epoch: 103, Train Loss: 1.0804\n",
            "Epoch: 104, Train Loss: 1.0743\n",
            "Epoch: 105, Train Loss: 1.0795\n",
            "Epoch: 106, Train Loss: 1.0671\n",
            "Epoch: 107, Train Loss: 1.0700\n",
            "Epoch: 108, Train Loss: 1.0723\n",
            "Epoch: 109, Train Loss: 1.0678\n",
            "Epoch: 110, Train Loss: 1.0651\n",
            "Epoch: 111, Train Loss: 1.0663\n",
            "Epoch: 112, Train Loss: 1.0666\n",
            "Epoch: 113, Train Loss: 1.0673\n",
            "Epoch: 114, Train Loss: 1.0676\n",
            "Epoch: 115, Train Loss: 1.0686\n",
            "Epoch: 116, Train Loss: 1.0684\n",
            "Epoch: 117, Train Loss: 1.0680\n",
            "Epoch: 118, Train Loss: 1.0677\n",
            "Epoch: 119, Train Loss: 1.0675\n",
            "Epoch: 120, Train Loss: 1.0672\n",
            "Epoch: 121, Train Loss: 1.0668\n",
            "Epoch: 122, Train Loss: 1.0663\n",
            "Epoch: 123, Train Loss: 1.0661\n",
            "Epoch: 124, Train Loss: 1.0660\n",
            "Epoch: 125, Train Loss: 1.0658\n",
            "Epoch: 126, Train Loss: 1.0656\n",
            "Epoch: 127, Train Loss: 1.0654\n",
            "Epoch: 128, Train Loss: 1.0654\n",
            "Epoch: 129, Train Loss: 1.0652\n",
            "Epoch: 130, Train Loss: 1.0648\n",
            "Epoch: 131, Train Loss: 1.0645\n",
            "Epoch: 132, Train Loss: 1.0643\n",
            "Epoch: 133, Train Loss: 1.0639\n",
            "Epoch: 134, Train Loss: 1.0635\n",
            "Epoch: 135, Train Loss: 1.0633\n",
            "Epoch: 136, Train Loss: 1.0627\n",
            "Epoch: 137, Train Loss: 1.0624\n",
            "Epoch: 138, Train Loss: 1.0627\n",
            "Epoch: 139, Train Loss: 1.0621\n",
            "Epoch: 140, Train Loss: 1.0616\n",
            "Epoch: 141, Train Loss: 1.0613\n",
            "Epoch: 142, Train Loss: 1.0606\n",
            "Epoch: 143, Train Loss: 1.0601\n",
            "Epoch: 144, Train Loss: 1.0598\n",
            "Epoch: 145, Train Loss: 1.0592\n",
            "Epoch: 146, Train Loss: 1.0588\n",
            "Epoch: 147, Train Loss: 1.0583\n",
            "Epoch: 148, Train Loss: 1.0581\n",
            "Epoch: 149, Train Loss: 1.0575\n",
            "Epoch: 150, Train Loss: 1.0574\n",
            "Epoch: 151, Train Loss: 1.0572\n",
            "Epoch: 152, Train Loss: 1.0568\n",
            "Epoch: 153, Train Loss: 1.0568\n",
            "Epoch: 154, Train Loss: 1.0565\n",
            "Epoch: 155, Train Loss: 1.0539\n",
            "Epoch: 156, Train Loss: 1.0606\n",
            "Epoch: 157, Train Loss: 1.1662\n",
            "Epoch: 158, Train Loss: 1.0571\n",
            "Epoch: 159, Train Loss: 1.0921\n",
            "Epoch: 160, Train Loss: 1.0825\n",
            "Epoch: 161, Train Loss: 1.0626\n",
            "Epoch: 162, Train Loss: 1.0746\n",
            "Epoch: 163, Train Loss: 1.0757\n",
            "Epoch: 164, Train Loss: 1.0982\n",
            "Epoch: 165, Train Loss: 1.0783\n",
            "Epoch: 166, Train Loss: 1.0706\n",
            "Epoch: 167, Train Loss: 1.0800\n",
            "Epoch: 168, Train Loss: 1.0733\n",
            "Epoch: 169, Train Loss: 1.0917\n",
            "Epoch: 170, Train Loss: 1.0775\n",
            "Epoch: 171, Train Loss: 1.0736\n",
            "Epoch: 172, Train Loss: 1.0717\n",
            "Epoch: 173, Train Loss: 1.0724\n",
            "Epoch: 174, Train Loss: 1.0740\n",
            "Epoch: 175, Train Loss: 1.0745\n",
            "Epoch: 176, Train Loss: 1.0747\n",
            "Epoch: 177, Train Loss: 1.0747\n",
            "Epoch: 178, Train Loss: 1.0746\n",
            "Epoch: 179, Train Loss: 1.0745\n",
            "Epoch: 180, Train Loss: 1.0742\n",
            "Epoch: 181, Train Loss: 1.0739\n",
            "Epoch: 182, Train Loss: 1.0738\n",
            "Epoch: 183, Train Loss: 1.0736\n",
            "Epoch: 184, Train Loss: 1.0735\n",
            "Epoch: 185, Train Loss: 1.0734\n",
            "Epoch: 186, Train Loss: 1.0731\n",
            "Epoch: 187, Train Loss: 1.0730\n",
            "Epoch: 188, Train Loss: 1.0728\n",
            "Epoch: 189, Train Loss: 1.0726\n",
            "Epoch: 190, Train Loss: 1.0725\n",
            "Epoch: 191, Train Loss: 1.0723\n",
            "Epoch: 192, Train Loss: 1.0723\n",
            "Epoch: 193, Train Loss: 1.0723\n",
            "Epoch: 194, Train Loss: 1.0722\n",
            "Epoch: 195, Train Loss: 1.0720\n",
            "Epoch: 196, Train Loss: 1.0717\n",
            "Epoch: 197, Train Loss: 1.0715\n",
            "Epoch: 198, Train Loss: 1.0714\n",
            "Epoch: 199, Train Loss: 1.0713\n",
            "Epoch: 200, Train Loss: 1.0712\n",
            "Epoch: 201, Train Loss: 1.0710\n",
            "Epoch: 202, Train Loss: 1.0708\n",
            "Epoch: 203, Train Loss: 1.0707\n",
            "Epoch: 204, Train Loss: 1.0705\n",
            "Epoch: 205, Train Loss: 1.0703\n",
            "Epoch: 206, Train Loss: 1.0702\n",
            "Epoch: 207, Train Loss: 1.0700\n",
            "Epoch: 208, Train Loss: 1.0699\n",
            "Epoch: 209, Train Loss: 1.0697\n",
            "Epoch: 210, Train Loss: 1.0696\n",
            "Epoch: 211, Train Loss: 1.0694\n",
            "Epoch: 212, Train Loss: 1.0692\n",
            "Epoch: 213, Train Loss: 1.0690\n",
            "Epoch: 214, Train Loss: 1.0688\n",
            "Epoch: 215, Train Loss: 1.0687\n",
            "Epoch: 216, Train Loss: 1.0685\n",
            "Epoch: 217, Train Loss: 1.0683\n",
            "Epoch: 218, Train Loss: 1.0681\n",
            "Epoch: 219, Train Loss: 1.0679\n",
            "Epoch: 220, Train Loss: 1.0677\n",
            "Epoch: 221, Train Loss: 1.0675\n",
            "Epoch: 222, Train Loss: 1.0673\n",
            "Epoch: 223, Train Loss: 1.0671\n",
            "Epoch: 224, Train Loss: 1.0669\n",
            "Epoch: 225, Train Loss: 1.0667\n",
            "Epoch: 226, Train Loss: 1.0665\n",
            "Epoch: 227, Train Loss: 1.0664\n",
            "Epoch: 228, Train Loss: 1.0662\n",
            "Epoch: 229, Train Loss: 1.0660\n",
            "Epoch: 230, Train Loss: 1.0659\n",
            "Epoch: 231, Train Loss: 1.0657\n",
            "Epoch: 232, Train Loss: 1.0655\n",
            "Epoch: 233, Train Loss: 1.0654\n",
            "Epoch: 234, Train Loss: 1.0652\n",
            "Epoch: 235, Train Loss: 1.0651\n",
            "Epoch: 236, Train Loss: 1.0650\n",
            "Epoch: 237, Train Loss: 1.0648\n",
            "Epoch: 238, Train Loss: 1.0647\n",
            "Epoch: 239, Train Loss: 1.0646\n",
            "Epoch: 240, Train Loss: 1.0645\n",
            "Epoch: 241, Train Loss: 1.0644\n",
            "Epoch: 242, Train Loss: 1.0642\n",
            "Epoch: 243, Train Loss: 1.0641\n",
            "Epoch: 244, Train Loss: 1.0640\n",
            "Epoch: 245, Train Loss: 1.0639\n",
            "Epoch: 246, Train Loss: 1.0637\n",
            "Epoch: 247, Train Loss: 1.0636\n",
            "Epoch: 248, Train Loss: 1.0634\n",
            "Epoch: 249, Train Loss: 1.0632\n",
            "Epoch: 250, Train Loss: 1.0630\n",
            "Epoch: 251, Train Loss: 1.0628\n",
            "Epoch: 252, Train Loss: 1.0626\n",
            "Epoch: 253, Train Loss: 1.0625\n",
            "Epoch: 254, Train Loss: 1.0623\n",
            "Epoch: 255, Train Loss: 1.0622\n",
            "Epoch: 256, Train Loss: 1.0621\n",
            "Epoch: 257, Train Loss: 1.0620\n",
            "Epoch: 258, Train Loss: 1.0618\n",
            "Epoch: 259, Train Loss: 1.0617\n",
            "Epoch: 260, Train Loss: 1.0616\n",
            "Epoch: 261, Train Loss: 1.0615\n",
            "Epoch: 262, Train Loss: 1.0614\n",
            "Epoch: 263, Train Loss: 1.0613\n",
            "Epoch: 264, Train Loss: 1.0612\n",
            "Epoch: 265, Train Loss: 1.0612\n",
            "Epoch: 266, Train Loss: 1.0611\n",
            "Epoch: 267, Train Loss: 1.0610\n",
            "Epoch: 268, Train Loss: 1.0609\n",
            "Epoch: 269, Train Loss: 1.0609\n",
            "Epoch: 270, Train Loss: 1.0608\n",
            "Epoch: 271, Train Loss: 1.0607\n",
            "Epoch: 272, Train Loss: 1.0606\n",
            "Epoch: 273, Train Loss: 1.0606\n",
            "Epoch: 274, Train Loss: 1.0605\n",
            "Epoch: 275, Train Loss: 1.0604\n",
            "Epoch: 276, Train Loss: 1.0603\n",
            "Epoch: 277, Train Loss: 1.0603\n",
            "Epoch: 278, Train Loss: 1.0602\n",
            "Epoch: 279, Train Loss: 1.0601\n",
            "Epoch: 280, Train Loss: 1.0600\n",
            "Epoch: 281, Train Loss: 1.0600\n",
            "Epoch: 282, Train Loss: 1.0599\n",
            "Epoch: 283, Train Loss: 1.0598\n",
            "Epoch: 284, Train Loss: 1.0597\n",
            "Epoch: 285, Train Loss: 1.0596\n",
            "Epoch: 286, Train Loss: 1.0595\n",
            "Epoch: 287, Train Loss: 1.0594\n",
            "Epoch: 288, Train Loss: 1.0594\n",
            "Epoch: 289, Train Loss: 1.0593\n",
            "Epoch: 290, Train Loss: 1.0592\n",
            "Epoch: 291, Train Loss: 1.0591\n",
            "Epoch: 292, Train Loss: 1.0590\n",
            "Epoch: 293, Train Loss: 1.0589\n",
            "Epoch: 294, Train Loss: 1.0589\n",
            "Epoch: 295, Train Loss: 1.0588\n",
            "Epoch: 296, Train Loss: 1.0587\n",
            "Epoch: 297, Train Loss: 1.0586\n",
            "Epoch: 298, Train Loss: 1.0585\n",
            "Epoch: 299, Train Loss: 1.0584\n",
            "Epoch: 300, Train Loss: 1.0583\n",
            "Epoch: 301, Train Loss: 1.0582\n",
            "Epoch: 302, Train Loss: 1.0582\n",
            "Epoch: 303, Train Loss: 1.0581\n",
            "Epoch: 304, Train Loss: 1.0580\n",
            "Epoch: 305, Train Loss: 1.0579\n",
            "Epoch: 306, Train Loss: 1.0578\n",
            "Epoch: 307, Train Loss: 1.0577\n",
            "Epoch: 308, Train Loss: 1.0576\n",
            "Epoch: 309, Train Loss: 1.0575\n",
            "Epoch: 310, Train Loss: 1.0596\n",
            "Epoch: 311, Train Loss: 1.0643\n",
            "Epoch: 312, Train Loss: 1.0592\n",
            "Epoch: 313, Train Loss: 1.0595\n",
            "Epoch: 314, Train Loss: 1.0612\n",
            "Epoch: 315, Train Loss: 1.0580\n",
            "Epoch: 316, Train Loss: 1.1030\n",
            "Epoch: 317, Train Loss: 1.0656\n",
            "Epoch: 318, Train Loss: 1.0719\n",
            "Epoch: 319, Train Loss: 1.0690\n",
            "Epoch: 320, Train Loss: 1.0690\n",
            "Epoch: 321, Train Loss: 1.0694\n",
            "Epoch: 322, Train Loss: 1.0747\n",
            "Epoch: 323, Train Loss: 1.0729\n",
            "Epoch: 324, Train Loss: 1.0863\n",
            "Epoch: 325, Train Loss: 1.0797\n",
            "Epoch: 326, Train Loss: 1.0759\n",
            "Epoch: 327, Train Loss: 1.0754\n",
            "Epoch: 328, Train Loss: 1.0778\n",
            "Epoch: 329, Train Loss: 1.0772\n",
            "Epoch: 330, Train Loss: 1.0734\n",
            "Epoch: 331, Train Loss: 1.0711\n",
            "Epoch: 332, Train Loss: 1.0696\n",
            "Epoch: 333, Train Loss: 1.0695\n",
            "Epoch: 334, Train Loss: 1.0700\n",
            "Epoch: 335, Train Loss: 1.0705\n",
            "Epoch: 336, Train Loss: 1.0704\n",
            "Epoch: 337, Train Loss: 1.0701\n",
            "Epoch: 338, Train Loss: 1.0701\n",
            "Epoch: 339, Train Loss: 1.0700\n",
            "Epoch: 340, Train Loss: 1.0700\n",
            "Epoch: 341, Train Loss: 1.0699\n",
            "Epoch: 342, Train Loss: 1.0699\n",
            "Epoch: 343, Train Loss: 1.0699\n",
            "Epoch: 344, Train Loss: 1.0697\n",
            "Epoch: 345, Train Loss: 1.0696\n",
            "Epoch: 346, Train Loss: 1.0694\n",
            "Epoch: 347, Train Loss: 1.0692\n",
            "Epoch: 348, Train Loss: 1.0691\n",
            "Epoch: 349, Train Loss: 1.0690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "cost = 0\n",
        "masking = mask_tensor\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    if time == 257:\n",
        "        break\n",
        "    masking.to(device)\n",
        "    snapshot.to(device)\n",
        "    if time == 0:\n",
        "        graph_seq_embed = torch.empty((0, 0)).to(device)\n",
        "    else: \n",
        "        graph_seq_embed = torch.cat(graph_seq_embed_list, dim=0).to(device)\n",
        "    y_hat, cur_graph_seq_embed = model(time, graph_seq_embed, masking[time].to(device), snapshot.edge_index, snapshot.x, snapshot.edge_attr[:, None])\n",
        "    # print(f\"y_hat size: {y_hat.size()}\")\n",
        "    # print(f\"y_hat: {y_hat}\")\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "    graph_seq_embed_list.append(cur_graph_seq_embed)\n",
        "cost = cost / (time)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))"
      ],
      "metadata": {
        "id": "G02dPLqUE-53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f63b07-27f1-499b-95ab-9b63ec68474a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.9073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "wandb.save(\"mgn_attention_qm9_1_res_4_clusters.h5\")\n",
        "torch.save(model.state_dict(), \"mgn_attention_qm9_1_res_4_clusters.pth\")\n",
        "files.download(\"mgn_attention_qm9_1_res_4_clusters.pth\")"
      ],
      "metadata": {
        "id": "yQYIDHtCsYXX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d4b37f30-e784-4454-b9d7-6a2b769e03df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30b5e199-d2f3-44b5-a3a8-15b62055d5ce\", \"mgn_attention_qm9_1_res_4_clusters.pth\", 1343733)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deprecated code"
      ],
      "metadata": {
        "id": "b5XWb2l-0LEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset testing\n",
        "# from torch_geometric.datasets import ZINC, QM9, TUDataset, KarateClub, GNNBenchmarkDataset\n",
        "\n",
        "# # dataset = ZINC('data/ZINC')\n",
        "# dataset = QM9(root='data/QM7b')\n",
        "# # dataset = TUDataset(root='data/TUDataset', name='PROTEINS')\n",
        "# # dataset = KarateClub()\n",
        "# # dataset = GNNBenchmarkDataset(root='data/GNNBenchmarkDataset', name='MNIST')\n",
        "\n",
        "# print(f'Dataset: {dataset}:')\n",
        "# print('====================')\n",
        "# print(f'Number of graphs: {len(dataset)}')\n",
        "# print(f'Number of features: {dataset.num_features}')\n",
        "# print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "# data = dataset[0] # Get the first graph object\n",
        "\n",
        "# print()\n",
        "# print(data)\n",
        "# print('=============================================================')\n",
        "\n",
        "# # Gather some statistics about the first graph\n",
        "# print(f'Number of nodes: {data.num_nodes}')\n",
        "# print(f'Number of edges: {data.num_edges}')\n",
        "# print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "# print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "# print(f'Has self-loops: {data.has_self_loops()}')\n",
        "# print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "id": "npW58Keh2bNs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = dataset.shuffle()\n",
        "\n",
        "# train_dataset = dataset[:10000]\n",
        "# test_dataset = dataset[10000:11000]\n",
        "\n",
        "# print(f'Number of training graphs: {len(train_dataset)}')\n",
        "# print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "X3A-6D-K3w8O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Minibatching the dataset \n",
        "# from torch_geometric.loader import DataLoader\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, shuffle=False)\n",
        "\n",
        "# # Compute the data mean and standard deviation\n",
        "# all_y = []\n",
        "# for data in train_loader:\n",
        "#   all_y.append(data.y.detach().numpy())\n",
        "# for data in test_loader:\n",
        "#   all_y.append(data.y.detach().numpy())\n",
        "# all_y = np.concatenate(all_y)\n",
        "# mean_y = np.mean(all_y)\n",
        "# std_y = np.std(all_y)\n",
        "# print('Mean:', mean_y)\n",
        "# print('STD:', std_y)"
      ],
      "metadata": {
        "id": "zrWDOD1B39hd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import Javascript\n",
        "# display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "# model = MGN(\n",
        "#     clusters=[4],\n",
        "#     num_layers=4,\n",
        "#     node_dim=dataset.num_features,\n",
        "#     edge_dim=dataset.num_edge_features,\n",
        "#     hidden_dim=64,\n",
        "#     z_dim=16,\n",
        "#     num_classes=dataset.num_classes\n",
        "# ).to(device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "# criterion = torch.nn.MSELoss(reduction='mean')\n",
        "\n",
        "# param_count = count_parameters(model)\n",
        "\n",
        "# def train():\n",
        "#     model.train()\n",
        "\n",
        "#     for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "#         data.to(device)\n",
        "#         predict, latent, outputs = model(data.edge_index, data.x, data.edge_attr)  # Perform a single forward pass.\n",
        "\n",
        "#         # Normalization\n",
        "#         new_y = (data.y.detach().cpu() - mean_y) / std_y\n",
        "#         new_y = new_y.to(device)\n",
        "\n",
        "#         # loss = criterion(predict[None, :], data.y)  # Compute the loss.\n",
        "#         loss = criterion(predict[None, :], new_y)  # Compute the loss.\n",
        "\n",
        "#         loss.backward()  # Derive gradients.\n",
        "#         optimizer.step()  # Update parameters based on gradients.\n",
        "#         optimizer.zero_grad()  # Clear gradients.\n",
        "\n",
        "# def test(loader):\n",
        "#     model.eval()\n",
        "\n",
        "#     correct = 0\n",
        "#     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "#         data.to(device)\n",
        "#         predict, latent, outputs = model(data.edge_index, data.x, data.edge_attr)  \n",
        "\n",
        "#         # Normalization\n",
        "#         new_y = (data.y.detach().cpu() - mean_y) / std_y\n",
        "#         new_y = new_y.to(device)\n",
        "\n",
        "#         # modelLoss = criterion(predict[None, :], data.y)\n",
        "#         modelLoss = criterion(predict[None, :], new_y)\n",
        "\n",
        "#     return modelLoss  # Derive ratio of correct predictions.\n",
        "\n",
        "\n",
        "# for epoch in range(200):\n",
        "#     train()\n",
        "#     train_loss = test(train_loader)\n",
        "#     test_loss = test(test_loader)\n",
        "#     wandb.log({\"train_loss\": train_loss, \"test_loss\": test_loss})\n",
        "#     print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
      ],
      "metadata": {
        "id": "xhM4wbg04PVT"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}